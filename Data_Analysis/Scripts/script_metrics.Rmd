---
  title: "Rscript - 10 first calls, Titi alarm calls"
author: "Narbona Sabat√© L. & Berthet M."
output: pdf_document
editor_options: 
  chunk_output_type: console
---

  ```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This script uses function for the cfp package, that needs to be installed with command 
library(devtools)
devtools::install_github("gobbios/cfp")

Install and load the following packages:
  
```{r, message=FALSE, warning=FALSE}
library(cfp)
library(RColorBrewer)
library(tidyverse)

```

#1. What are the metrics of the sequences?
The aim of this script is to create a data file with, for each sequence, the type of predator, the location, the distance between the caller and the predator, and the different metrics.

# Function creation
```{r}
#Function to create a dataset template
DataFrame <- function(xdata=xdata,calls=0){
  
  #Calls of each sequences are given in column, transform them into character strings
  SeqCalls <- sapply(unique(xdata$Seq1), function(X) 
  paste0(xdata$Type_call[xdata$Seq1 == X], collapse=""))
  
  #Take the number of calls specified in the function. If calls = 0, it takes all the numbers of calls in the dataset
  if (calls == 0){ seqcall = SeqCalls }
  else{ seqcall = substr(SeqCalls,start = 1, stop = calls) }
  
  #Dataframe creation with all the relevant info for each sequence (Code of the sequence,
  #Group of the caller, type and location of the predator, distance predator-caller 
  #and call sequence) in one dataset (will be filled with metric values)
  xdata3 <- data.frame(seqID = unique(xdata$Seq1), group=as.character(xdata$Group[which(xdata$Nb_call==1)]),
                     ind=as.character(xdata$Ind[which(xdata$Nb_call==1)]), preda = as.character
                     (xdata$Cat_preda[which(xdata$Nb_call==1)]), 
                     loca = as.character(xdata$Location[which(xdata$Nb_call==1)]), 
                     dis = xdata$Distance[which(xdata$Nb_call==1)], seqcall = seqcall, 
                     first_call = substr(SeqCalls, start = 1, stop = 1))
  
  return(xdata3)
}

#Function callinterval to extract the call intervals from the sequences. 
#Output can be the mean call interval(outp="mean") 
#or the coefficient of variation of the call interval (outp="CV").
callintervals <- function(xdata, seqID, seqcol, starttime, endtime, outp="mean") { 
  temp <- xdata[xdata[, seqcol] == seqID, c(starttime, endtime)]
  res <- temp[2:nrow(temp), 1] - temp[1:(nrow(temp)-1) , 2]
  CV <- function(x) sd(x)/mean(x)
  if(outp == "mean") res <- mean(res)
  if(outp == "CV") res <- CV(res)
  return(res)
}

#Function to calculate Bayesian probabilities, with a Dirichlet distribution 
#where all alphas are the same.
bayesian_mean <- function(count_of_i, alpha_i, nb_of_events, k, multipl=1) {
  mean_i <- sum(count_of_i*multipl, alpha_i)/sum(nb_of_events, k*alpha_i) #"multipl" 
                                  #just in case the value was already a proportion
  return(mean_i)
}

#Funtion to calculate the peak of length-between-calls distributuion
calc_peak <- function(seqID, nb_calls, data=xdata) {
  lengths <- c()

  for (id in seqID) {
    data1 <- data[data$Seq1 == as.character(id),]
    {for (i in nb_calls){
      end <- data1[data1$Nb_call == i, "End_call"]
      begin <- data1[data1$Nb_call == i + 1, "Begin_call"]
      distance <- begin - end
      lengths <- c(lengths, distance)
      }
    }
  }
  max <- which.max(density(lengths)$y)
  peak <- density(lengths)$x[max]
  
  return(peak)
}

```

# Data Frame creation
```{r}
# read data from the excel file provided with the script, "predator presentations" dataset. 
#It contains XX sequences of 50 calls each.
data <- read.delim('Data/dataset_pred_prez_50-calls_chgd.txt')
xdata3 <- DataFrame(xdata=data, calls=10)
```

We begin to fill up the table with the metrics
## 1.a Metrics extraction
###Slope of elements, Bayesian proportion of calls, mean and CV of call interval

```{r}
#Fill the dataset with the slope of elements, the proportion of different calls, 
#the mean call interval and the coefficient of variation of the call interval.

for(i in 1:nrow(xdata3)) {
  xdata3$elementA[i] <- elementslope(as.character(xdata3$seqcall[i]), type="linear", target="A")
  xdata3$elementB[i] <- elementslope(as.character(xdata3$seqcall[i]), type="linear", target="B")
  xdata3$elementD[i] <- elementslope(as.character(xdata3$seqcall[i]), type="linear", target="D")
  xdata3$elementE[i] <- elementslope(as.character(xdata3$seqcall[i]), type="linear", target="E")
  xdata3$propA[i] <- elementprop(as.character(xdata3$seqcall[i]), target = "A")
  xdata3$propB[i] <- elementprop(as.character(xdata3$seqcall[i]), target = "B")
  xdata3$propC[i] <- elementprop(as.character(xdata3$seqcall[i]), target = "C")
  xdata3$propD[i] <- elementprop(as.character(xdata3$seqcall[i]), target = "D")
  xdata3$propE[i] <- elementprop(as.character(xdata3$seqcall[i]), target = "E")
  xdata3$meaninterval[i] <- callintervals(xdata, seqID=as.character(xdata3$seqID[i]), 
                            seqcol="Seq1", starttime="Begin_call", endtime="End_call", outp="mean")
  xdata3$CVinterval[i] <- callintervals(xdata, seqID=as.character(xdata3$seqID[i]), 
                          seqcol="Seq1", starttime="Begin_call", endtime="End_call", outp="CV")
}

#Bayesian proportion of A, B, C, BS and AS-calls (i.e. we add 1 to the number of calls 
#in the sequence and divide by 15 (5 possibilities of calls (A,B,C,BS, and AS) + 
#10 calls in the sequence))
xdata3$propA <- sapply(xdata3$propA, bayesian_mean, 1/5, 10, 5, 10)
xdata3$propB <- sapply(xdata3$propB, bayesian_mean, 1/5, 10, 5, 10)
xdata3$propC <- sapply(xdata3$propC, bayesian_mean, 1/5, 10, 5, 10)
xdata3$propD <- sapply(xdata3$propD, bayesian_mean, 1/5, 10, 5, 10)
xdata3$propE<- sapply(xdata3$propE, bayesian_mean, 1/5, 10, 5, 10)
```

### Computation of ngrams (using peak)
```{r}
#Creation of the columns for each Ngram (not taking C nor NA calls)

x <- 5 #ngram maximum wanted. If x=5, then we have bi, tri, tetra and penta-grams
NgramCalls <- unique(xdata$Type_call)[c(1:3, 6)]#We work with all call types except C and NA

for (i in 2:x){
  possible_ngrams <- expand.grid(rep(list(NgramCalls), times = i))
  for (row in 1:nrow(possible_ngrams)){
    c <- possible_ngrams[row,1]
    for (k in 2:i){ #paste the names of each call for each gram toghether
      b <- possible_ngrams[row,k]
      c <- paste0(b, c)
          }
      newname <-  paste0(i,"gram", "-", c)
      xdata3[,newname] <- 0
    }
}

#Calculate the peak of the calls
seqID <- unique(xdata$Seq1)
nb_calls <- head(unique(xdata$Nb_call), -1)

peak <- calc_peak(seqID, nb_calls, data=xdata)

# Fill the created columns with the count of Ngrams for each sequence
maxCalls=10 #Max number of calls in the sequence that we want to analyse (10 or 50 or...)
newname <- NA

#Code to fill the Ngrams columns. We look at a call and the ones behind that one to see whether they create a Ngram or not.
for (sequence in 1:nrow(xdata3)){
  for (num_call in 2:maxCalls){
   callType = xdata$Type_call[(xdata$Seq1 == xdata3$seqID[sequence]) & (xdata$Nb_call == num_call)] #call type associated to num_call
   k=1 #number of call(s) back that we look at (or the value N of the Ngram backward from the call "num_call")
    while (k <= (x-1) && k<num_call){ #We start with the call that is just before num_call and then go back until we reach the beginning of the sequence: we extract each bi, tri, N-gram (decided with the value of k) going backward
      begin_Firstcall_Ngram <- xdata$Begin_call[(xdata$Seq1 == xdata3$seqID[sequence]) 
                                                & (xdata$Nb_call == num_call-k+1)]
      end_Secondcall_Ngram <- xdata$End_call[(xdata$Seq1 == xdata3$seqID[sequence]) 
                                             & (xdata$Nb_call == num_call-k)]
        if(begin_Firstcall_Ngram - end_Secondcall_Ngram <= peak){ #extract the Ngram only if the duration in under the peak
            b <- xdata$Type_call[(xdata$Seq1 == xdata3$seqID[sequence]) & (xdata$Nb_call == num_call-k)] #b is the call type at k rank before num_call
            callType <- paste0(b, callType) #we add the letter b to the letter(s) that we had before, to create the name of the N-gram
             newname <- paste0(k+1,"gram", "-", callType) 
                if (!is.null(xdata3[sequence,newname])){
                    xdata3[sequence,newname] <- xdata3[sequence,newname]+1 #If the column already exists in the dataset, we add 1 in it (i.e. we count +1 N-gram of this type)
                } 
                else{}
              k <- k+1} 
          else { break }
    }
  }
}

#Autre solution:
#Par exemple, pour v?rifier, tu peux faire rowSums(xdata3[,20:1379]), qui va te calculer combien tu as de Ngram pour chaque s?quence. C'est ensuite assez facile ? la main de calculer si c'est juste. 
         
```
### Slope of ngrams and Bayesian proportion of ngrams

```{r}
#Create the  Ngrams Slope

#For each sequence, fill the slopes & calculate each Bayesian proportion of the ngrams
k <- 2 #To start with bigrams
for(i in k:x){
  gram <- paste0(i,"gram", "-")
  print(gram)
  id_columns <- grep(gram, names(xdata3)) #Take all the columns with the count of the given Ngram
  
  slopeGram_name <- paste0("slope","_", k, "gram")
  print(slopeGram_name)
  xdata3[,slopeGram_name] <- NA # Create a column for the slope of each iteration in the dataset

  for(row in 1:nrow(xdata3)) { #iterer sur les sequences
    temp <- data.frame(gram=character(), cnt=numeric(), stringsAsFactors=FALSE)
    totalGrams <- sum(xdata3[row, id_columns])
    alphaGram <- 1/length(id_columns)

      for (id in id_columns){ #Calculer le Slope pour chaque sequence
        temp[nrow(temp) + 1,] = c(names(xdata3[id]), xdata3[row,id])
        rownames(temp) <- as.character(temp$gram)
    
        xdata3[row, id] <- bayesian_mean(xdata3[row, id],alphaGram, totalGrams,
                                         length(id_columns))
      }
  
  temp <- sort(as.numeric(temp$cnt), decreasing = T)
  xdata3[row,slopeGram_name] <- lm(temp ~ c(1:length(temp)))$coefficients[2]
  
  }
}

#Sanity check for Bayesian proportions
id_bigram_columns <- grep("2gram-", names(xdata3))
id_trigram_columns <- grep("3gram-", names(xdata3))
id_tetragram_columns<-grep("4gram-", names(xdata3))
id_pentagram_columns <- grep("5gram-", names(xdata3))

for(row in 1:nrow(xdata3)) {
  print(sum(xdata3[row, id_bigram_columns]))
  print(sum(xdata3[row, id_trigram_columns]))
  print(sum(xdata3[row, id_tetragram_columns]))
  print(sum(xdata3[row, id_pentagram_columns]))
}
```

### Shannon entropy

Regression coefficient from the zero, first and second order Shannon entropy

```{r}
#Create the empty column
xdata3$entroSlope <- NA

#Extract the Zero, first and second order Shannon entropy 
#and extract the regression coefficient from the three values
for (i in 1:nrow(xdata3)) {
  # collect the three entropy values...
  temp <- entropy(as.character(xdata3$seqcall[i]), n=0)
  temp <- c(temp, entropy(as.character(xdata3$seqcall[i]), n=1))
  temp <- c(temp, entropy(as.character(xdata3$seqcall[i]), n=2))
  # and run regression
  xdata3$entroSlope[i] <- lm(temp ~ c(1:3))$coefficients[2]
  rm(temp)
}
```

### Bayesian probability of transition

```{r}
#Create a matrix of transition: first column= the first call; first row= the second call
strumat <- matrix(1, ncol=5, nrow=6)
colnames(strumat) <- c("A", "B", "C", "D", "E")
rownames(strumat) <- c("start", "A", "B", "C", "D", "E")
strumat[1,3] <- 0
strumat[1,4] <- 0
strumat[1,5] <- 0 #Define which transitions is not possible, 
#here it is not possible to begin the sequence with a C-call, BS-call (E) and a AS-call (D) since 
#it is not an alarm call

#Define what are the important transitions
targets <- c("start-A", "start-B", "A-A", "A-B", "A-C", "A-D", "A-E", "B-A", "B-B", "B-C", "B-D", "B-E", "D-A", "D-B", "D-C", "D-D", "D-E", "E-A", "E-B", "E-C", "E-D", "E-E")
# Integrate a column for each transition probability in the big dataset
xdata3 <- cbind(xdata3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA)
colnames(xdata3)[(ncol(xdata3)-21) : ncol(xdata3)] <- targets

#extract all the Bayesian transition probabilities that we selected before
for(i in 1:nrow(xdata3)) {
  temp <- transitions(as.character(xdata3$seqcall[i]), strucmat=strumat,
                      xstart=T, xstop=F, out="bayes")
  xdata3[i, targets] <- sapply(targets, function(X) 
    temp[strsplit(X, "-")[[1]][1], strsplit(X, "-")[[1]][2]])
  rm(temp)
}
#Give names of the transitions to the columns
targets <- c("tpSA", "tpSB", "tpAA", "tpAB", "tpAC", "tpAD", "tpAE", "tpBA", "tpBB", "tpBC", "tpBD", "tpBE", "tpDA", "tpDB", "tpDC", "tpDD", "tpDE", "tpEA", "tpEB", "tpEC", "tpED", "tpEE")
colnames(xdata3)[(ncol(xdata3)-21) : ncol(xdata3)] <- targets
rm(targets)

```

### Add social informations

```{r}

# read data from the excel file provided with the script, "additional_info". 
#It contains more info for each sequence
social_data <- read.delim('Data/dataset_pred_prez_50-calls_add-info.txt')

#Add it to xdata2
final_dataset_10 <- left_join(xdata3, social_data)

```
### Create a dataset from the data

```{r}
#Change the name to match with the number of calls taken into account in the metrics
write.table(final_dataset_10, file = "Data/10_calls_metrics.txt", sep = "\t",
            row.names = TRUE)
```